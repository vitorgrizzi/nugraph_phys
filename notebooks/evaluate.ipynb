{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6754838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6176aec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormOne(a):\n",
    "    return np.ones_like(a)/len(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd9c940",
   "metadata": {},
   "source": [
    "## Look into inference output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9a4dc6",
   "metadata": {},
   "source": [
    "Read file with inference results on validation data set and compute useful derived quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe252de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.read_hdf(\"infer_test_all2.h5\",mode='a')\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88f6e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total number of events:',len(pred.groupby(['run','subrun','event']).count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1ec907",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['MIP','HIP','shower','michel','diffuse']\n",
    "pred['sem_label'] = pd.Categorical(pred['y_semantic']).codes\n",
    "pred['sem_pred'] = pd.Categorical(pred['x_semantic']).codes\n",
    "pred['x_semantic_2nd'] = pred[classes].mask(pred[classes].eq(pred[classes].max(axis=1), axis=0)).idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52209f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred['isgood'] = pred.eval('sem_label==sem_pred').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc909cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred['true_score'] = 0\n",
    "pred['pred_score'] = 0\n",
    "pred['pred_score_2nd'] = 0\n",
    "for ctg in classes:\n",
    "    pred.loc[pred['y_semantic']==ctg, 'true_score'] = pred[ctg][pred['y_semantic']==ctg]\n",
    "    pred.loc[pred['x_semantic']==ctg, 'pred_score'] = pred[ctg][pred['x_semantic']==ctg]\n",
    "    pred.loc[pred['x_semantic_2nd']==ctg, 'pred_score_2nd'] = pred[ctg][pred['x_semantic_2nd']==ctg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9490a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred['pred_score_p'] = pred.eval('exp(pred_score)/(exp(MIP)+exp(HIP)+exp(shower)+exp(michel)+exp(diffuse))')\n",
    "pred['true_score_p'] = pred.eval('exp(true_score)/(exp(MIP)+exp(HIP)+exp(shower)+exp(michel)+exp(diffuse))')\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba9dcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pred.query('sem_label>=0')['sem_label'],weights=NormOne(pred.query('sem_label>=0')['sem_label']),bins=np.linspace(0,5,6),histtype='step',label='true')\n",
    "plt.hist(pred.query('sem_label>=0')['sem_pred'] ,weights=NormOne(pred.query('sem_label>=0')['sem_pred']),bins=np.linspace(0,5,6),histtype='step',label='predicted')\n",
    "plt.xlabel('category')\n",
    "plt.ylabel('fraction of hits')\n",
    "plt.title('abundance of categories in dataset')\n",
    "plt.xticks([0.5,1.5,2.5,3.5,4.5],classes)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6c921f",
   "metadata": {},
   "source": [
    "## Study network confidence in prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9501e25a",
   "metadata": {},
   "source": [
    "Here we use as a confidence score the softmax of the original scores, so that we get an estimate for the probability of the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3530c54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,ctg in enumerate(classes):\n",
    "    x=pred.query('sem_label>=0 and sem_pred==%i'%i)['pred_score_p']\n",
    "    plt.hist(x,weights=NormOne(x),bins=np.linspace(0,1,11),histtype='step',label=ctg)\n",
    "plt.legend(loc=2)\n",
    "plt.xlabel('score')\n",
    "plt.ylabel('fraction of entries')\n",
    "plt.title('predicted score per hit in different categories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c22fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pred.query('sem_label>=0 and isgood==1')['true_score_p']\n",
    "plt.hist(x,bins=np.linspace(0,1,11),histtype='step',label='correct')\n",
    "x=pred.query('sem_label>=0 and isgood==0')['true_score_p']\n",
    "plt.hist(x,bins=np.linspace(0,1,11),histtype='step',label='incorrect, true')\n",
    "x=pred.query('sem_label>=0 and isgood==0')['pred_score_p']\n",
    "plt.hist(x,bins=np.linspace(0,1,11),histtype='step',label='incorrect, pred')\n",
    "plt.xlabel('score')\n",
    "plt.ylabel('hit count')\n",
    "plt.yscale('log')\n",
    "plt.legend(loc=2)\n",
    "plt.title('score per hit')\n",
    "plt.show()\n",
    "\n",
    "x=pred.query('sem_label>=0 and isgood==1')['true_score_p']\n",
    "plt.hist(x,weights=NormOne(x),bins=np.linspace(0,1,11),histtype='step',label='correct')\n",
    "x=pred.query('sem_label>=0 and isgood==0')['true_score_p']\n",
    "plt.hist(x,weights=NormOne(x),bins=np.linspace(0,1,11),histtype='step',label='incorrect, true')\n",
    "x=pred.query('sem_label>=0 and isgood==0')['pred_score_p']\n",
    "plt.hist(x,weights=NormOne(x),bins=np.linspace(0,1,11),histtype='step',label='incorrect, pred')\n",
    "plt.xlabel('score')\n",
    "plt.ylabel('fraction of entries')\n",
    "plt.legend(loc=2)\n",
    "plt.title('score per hit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3610d58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pred.query('sem_label>=0 and isgood==1').eval('exp(pred_score_2nd-pred_score)')\n",
    "plt.hist(x,weights=NormOne(x),bins=np.linspace(0,1,11),histtype='step',label='correct')\n",
    "x=pred.query('sem_label>=0 and isgood==0').eval('exp(pred_score_2nd-pred_score)')\n",
    "plt.hist(x,weights=NormOne(x),bins=np.linspace(0,1,11),histtype='step',label='incorrect')\n",
    "plt.xlabel('exp(pred_2nd-pred)')\n",
    "plt.ylabel('a.u.')\n",
    "plt.legend(loc=1)\n",
    "plt.title('ratio of score for top 2 categories per hit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864e6672",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pred.query('sem_label>=0 and isgood==0').eval('exp(true_score-pred_score)')\n",
    "plt.hist(x,weights=NormOne(x),bins=np.linspace(0,1,11),histtype='step')\n",
    "plt.xlabel('exp(true_score-pred_score)')\n",
    "plt.ylabel('a.u.')\n",
    "plt.title('ratio of score of true to incorrectly predicted hit category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633ca0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = metrics.roc_curve(pred.query('sem_label>=0')['isgood'], pred.query('sem_label>=0')['pred_score_p'])\n",
    "plt.plot(fpr,tpr,label='all')\n",
    "for c in [0,1,2,3,4]:\n",
    "    fpr, tpr, _ = metrics.roc_curve(pred.query('sem_label==%i'%c)['isgood'], pred.query('sem_label==%i'%c)['pred_score_p'])\n",
    "    plt.plot(fpr,tpr,label=classes[c])\n",
    "    \n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC curves as a function of score probability')\n",
    "plt.legend(loc=7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eb55ad",
   "metadata": {},
   "source": [
    "## Confusion matrix by hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4028330",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.histogram2d(pred.query('sem_label>=0')['sem_pred'],pred.query('sem_label>=0')['sem_label'],bins=[np.linspace(0,5,6),np.linspace(0,5,6)])\n",
    "\n",
    "eff = (x[0].transpose() / x[0].sum(axis=1)).transpose()\n",
    "pur = x[0] / x[0].sum(axis=0)\n",
    "\n",
    "fig = plt.figure(figsize=(7, 6))\n",
    "plt.imshow(eff,origin='lower',cmap='copper')\n",
    "for i in range(len(eff[0])):\n",
    "    for j in range(len(eff[0])):\n",
    "        text = plt.text(j, i, \"%.2f\"%eff[i, j],ha=\"center\", va=\"center\", color=\"w\")\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"assigned label\")\n",
    "ax = plt.gca()\n",
    "ax.set_xticklabels(['','MIP','HIP','SHR','MCL','DFS'])\n",
    "ax.set_yticklabels(['','MIP','HIP','SHR','MCL','DFS'])\n",
    "plt.ylabel(\"true label\")\n",
    "plt.title('efficiency (by hit)')\n",
    "plt.tight_layout()\n",
    "fig.show()\n",
    "\n",
    "fig = plt.figure(figsize=(7, 6))\n",
    "plt.imshow(pur,origin='lower',cmap='copper')\n",
    "for i in range(len(pur[0])):\n",
    "    for j in range(len(pur[0])):\n",
    "        text = plt.text(j, i, \"%.2f\"%pur[i, j],ha=\"center\", va=\"center\", color=\"w\")\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"assigned label\")\n",
    "ax = plt.gca()\n",
    "ax.set_xticklabels(['','MIP','HIP','SHR','MCL','DFS'])\n",
    "ax.set_yticklabels(['','MIP','HIP','SHR','MCL','DFS'])\n",
    "plt.ylabel(\"true label\")\n",
    "plt.title('purity (by hit)')\n",
    "plt.tight_layout()\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de87e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('overall accuracy=',pred.query('sem_label>=0')['isgood'].sum()/pred.query('sem_label>=0')['isgood'].count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
